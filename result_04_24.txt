# python experiment.py --min_df 2 --n_gram 3  --use_linked_commits_only False --use_issue_classifier True --use_stacking_ensemble True --use-patch-context-lines False --tf-idf-threshold 0.005 -w 0.1 -w 0.5 -w 0.9 --dataset full_dataset_with_all_features.txt
Dataset: MSR2019/experiment/full_dataset_with_all_features.txt
Running process with these options:
    Data set size: Full data
    Ignore number as token: True
    Use github issue: True
    Use jira ticket: True
    Use comments: True
    Use bag of words: True
    Positive weights: [0.1, 0.5, 0.9]
    Max N-gram: 3
    Min document frequency: 2
    Use linked commit only: False
    Use issue classifier: True
    Fold to run: 10
    Use stacking ensemble: True
    Tf-idf threshold: 0.005
    Use patch context lines: False
    Unlabeled size: 0
Processing fold number: 1
Current processing weight set (0.1,0.9)
Message F1: 0.7431192660550459
Issue F1: 0.85
Patch F1: 0.5853658536585366
Current processing weight set (0.5,0.5)
Message F1: 0.7652173913043477
Issue F1: 0.85
Patch F1: 0.5756457564575647
Current processing weight set (0.9,0.09999999999999998)
Message F1: 0.761904761904762
Issue F1: 0.85
Patch F1: 0.5733788395904438
Processing fold number: 2
Current processing weight set (0.1,0.9)
Message F1: 0.6790123456790124
Issue F1: 0.7714285714285715
Patch F1: 0.5560538116591929
Current processing weight set (0.5,0.5)
Message F1: 0.6820809248554912
Issue F1: 0.7941176470588236
Patch F1: 0.5606694560669456
Current processing weight set (0.9,0.09999999999999998)
Message F1: 0.7252747252747251
Issue F1: 0.8059701492537314
Patch F1: 0.5967741935483871
Processing fold number: 3
Current processing weight set (0.1,0.9)
Message F1: 0.7448979591836735
Issue F1: 0.7407407407407408
Patch F1: 0.6244725738396625
Current processing weight set (0.5,0.5)
Message F1: 0.8019323671497586
Issue F1: 0.759493670886076
Patch F1: 0.6008230452674898
Current processing weight set (0.9,0.09999999999999998)
Message F1: 0.8173076923076924
Issue F1: 0.7407407407407408
Patch F1: 0.5629629629629629
Processing fold number: 4
Current processing weight set (0.1,0.9)
Message F1: 0.7674418604651162
Issue F1: 0.8571428571428572
Patch F1: 0.5673076923076924
Current processing weight set (0.5,0.5)
Message F1: 0.7777777777777777
Issue F1: 0.845360824742268
Patch F1: 0.5739910313901346
Current processing weight set (0.9,0.09999999999999998)
Message F1: 0.770053475935829
Issue F1: 0.845360824742268
Patch F1: 0.6026200873362446
Processing fold number: 5
Current processing weight set (0.1,0.9)
Message F1: 0.75
Issue F1: 0.8275862068965518
Patch F1: 0.5847457627118645
Current processing weight set (0.5,0.5)
Message F1: 0.7632850241545894
Issue F1: 0.7912087912087913
Patch F1: 0.611764705882353
Current processing weight set (0.9,0.09999999999999998)
Message F1: 0.7714285714285715
Issue F1: 0.8
Patch F1: 0.6136363636363636
Processing fold number: 6
Current processing weight set (0.1,0.9)
Message F1: 0.7339449541284403
Issue F1: 0.8282828282828283
Patch F1: 0.5931558935361217
Current processing weight set (0.5,0.5)
Message F1: 0.7636363636363637
Issue F1: 0.816326530612245
Patch F1: 0.5512367491166078
Current processing weight set (0.9,0.09999999999999998)
Message F1: 0.7543859649122807
Issue F1: 0.816326530612245
Patch F1: 0.6
Processing fold number: 7
Current processing weight set (0.1,0.9)
Message F1: 0.7329842931937174
Issue F1: 0.8450704225352113
Patch F1: 0.5739130434782609
Current processing weight set (0.5,0.5)
Message F1: 0.7244897959183675
Issue F1: 0.8108108108108109
Patch F1: 0.5655737704918034
Current processing weight set (0.9,0.09999999999999998)
Message F1: 0.758974358974359
Issue F1: 0.7792207792207793
Patch F1: 0.584
Processing fold number: 8
Current processing weight set (0.1,0.9)
Message F1: 0.7632850241545893
Issue F1: 0.8421052631578948
Patch F1: 0.5892116182572613
Current processing weight set (0.5,0.5)
Message F1: 0.7782805429864253
Issue F1: 0.8533333333333333
Patch F1: 0.6159695817490495
Current processing weight set (0.9,0.09999999999999998)
Message F1: 0.7577092511013216
Issue F1: 0.8311688311688312
Patch F1: 0.6096654275092936
Processing fold number: 9
Current processing weight set (0.1,0.9)
Message F1: 0.7121951219512194
Issue F1: 0.8055555555555555
Patch F1: 0.6265060240963856
Current processing weight set (0.5,0.5)
Message F1: 0.712962962962963
Issue F1: 0.7887323943661971
Patch F1: 0.6183206106870228
Current processing weight set (0.9,0.09999999999999998)
Message F1: 0.7488584474885844
Issue F1: 0.8055555555555555
Patch F1: 0.6315789473684211
Processing fold number: 10
Current processing weight set (0.1,0.9)
Message F1: 0.7557603686635944
Issue F1: 0.8155339805825242
Patch F1: 0.6165413533834586
Current processing weight set (0.5,0.5)
Message F1: 0.7336244541484717
Issue F1: 0.8269230769230769
Patch F1: 0.6231884057971016
Current processing weight set (0.9,0.09999999999999998)
Message F1: 0.7594936708860759
Issue F1: 0.8269230769230769
Patch F1: 0.6344827586206897
Training result for positive weight: 0.1, negative weight: 0.9
Log message mean precision: 0.8645197877814775
Log message mean recall: 0.6457290540322453
Log message mean f1: 0.7382641193474409
Issue mean precision: 0.8093256168505392
Issue mean recall: 0.8303197120902039
Issue mean f1: 0.8183446426322736
Patch mean precision: 0.5606877705947926
Patch mean recall: 0.6288045924445178
Patch mean f1: 0.5917273626928437
Joint-model mean precision: 0.3872623897317574
Joint-model mean recall: 0.375724682561259
Joint-model mean f1: 0.38012734492269284
Joint-model mean AUC-ROC: 0.7007922377926887
Joint-model mean AUC-PR: 0.4087883843687347
Training result for positive weight: 0.5, negative weight: 0.5
Log message mean precision: 0.823797258147384
Log message mean recall: 0.6900119529447445
Log message mean f1: 0.7503287604894555
Issue mean precision: 0.8049732578810016
Issue mean recall: 0.8254356034918097
Issue mean f1: 0.8136307079941622
Patch mean precision: 0.5289200558276935
Patch mean recall: 0.6680002753860673
Patch mean f1: 0.5897183112906073
Joint-model mean precision: 0.37342669193015776
Joint-model mean recall: 0.35196182030916306
Joint-model mean f1: 0.36123283939153733
Joint-model mean AUC-ROC: 0.6898616170147805
Joint-model mean AUC-PR: 0.39293726018676606
Training result for positive weight: 0.9, negative weight: 0.09999999999999998
Log message mean precision: 0.8161425869865943
Log message mean recall: 0.716348043457091
Log message mean f1: 0.7625390920214201
Issue mean precision: 0.7954743495738485
Issue mean recall: 0.8281383061945122
Issue mean f1: 0.8101266488217227
Patch mean precision: 0.5217519483243652
Patch mean recall: 0.7097067758508647
Patch mean f1: 0.6009099580572806
Joint-model mean precision: 0.3624496321992447
Joint-model mean recall: 0.3357334039683052
Joint-model mean f1: 0.3473542435399072
Joint-model mean AUC-ROC: 0.6869752461126113
Joint-model mean AUC-PR: 0.38099680715588957
Writing false cases at 2022-04-24_13_25_49.354444
